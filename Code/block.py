# -*- coding: utf-8 -*-
"""Blocks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eGHx33J-0M1QbIbCKHYLpLirZimzuMnA
"""

import torch 
import torch.nn as nn
import torchvision.transforms as transforms
import torch.functional as F
from PIL import Image
import numpy as np

"""##Encoder"""

#Regular Convolution Block
def convBlock(in_channel, in_hidden_channel):
    output = nn.Sequential(                                                     #Convolution block branch from the input image
        nn.Conv2d(in_channel, in_hidden_channel, kernel_size=3, stride=1, 
                  padding=1),                                                   #the general formula for keeping zero padding so that spatial size of input and output volume remains same is (k-1)/2; k = kernel_size
        nn.BatchNorm2d(in_hidden_channel),                                      #To determine the spatial size of output volume = (I-K+2P)/S; I=input_size, K=Kernel_size, P=Zero_padding, S=stride
        nn.ReLU(inplace=True),
        nn.Conv2d(in_hidden_channel, in_hidden_channel, kernel_size=3, stride=1, 
                  padding=1),
        nn.BatchNorm2d(in_hidden_channel),
        nn.ReLU(inplace=True),
    )                         

    return output

#Projection Convolution Block: It is a normal 1x1 kernel size convolution where, 
#the channels are altered depending upon the internal channel ratio which,
# is divided from the input channel to get the output channel
def projectionConv(in_channel, internal_channel_ratio, kernel_size, stride, padding = 0):
    out_channel = int(in_channel/internal_channel_ratio)
    output = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding= padding),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return output

#Assymetric Convolution Block: It gives us the features extracted from both
#columwise and rowwise traversing of filter-size since the lanes can be 
#horizontal as well vertical and in general strain running case the lane features
#will be in the columns only.
def assymetricConv(in_channel, hidden_channel, out_channel, padding):
    output = nn.Sequential(
        nn.Conv2d(in_channel, hidden_channel, kernel_size=(3,1), stride=1, padding=padding),
        nn.BatchNorm2d(hidden_channel),
        nn.ReLU(inplace=True),
        nn.Conv2d(hidden_channel, out_channel, kernel_size=(1,5), stride=1),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return output

#Expansion Convolution Block : It is also a normal 1x1 kernel size convolution where,
#the channel are altered depending upon the internal channel ratio which is 
#multiplied to the input channel to get the output channel
def expansionConv(in_channel, internal_channel_ratio, kernel_size, stride, padding=0):
    out_channel = int(in_channel * internal_channel_ratio)
    output = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding= padding),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return output

#regular convolution block
def convBlock(in_channel, out_channel, kernel_size, stride, padding = 0):
    output = nn.Sequential(
        nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return output

#TransConvolution
def transConv(in_channel, out_channel, kernel_size, stride):
    output = nn.Sequential(
        nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride),
        nn.BatchNorm2d(out_channel),
        nn.ReLU(inplace=True)
    )
    return output

"""Initial Block"""

#initial Block
def initial_block(image):                                                       #(1x1x256x256) 
    convBlock1 = convBlock(1, 32)                                               #(1x32x256x256) Since Padding =1
    convBlock2 = convBlock(32, 64)                                              #(1x64x256x256) Since Padding =1 
    output_1 = nn.MaxPool2d(kernel_size=2, stride=2)(                       
        convBlock2(convBlock1(image)))                                          #(1x64x128x128)
    output_2 = nn.MaxPool2d(kernel_size=2, stride=2)(image)                     #(1x1x128x128)                                          
    output = torch.cat([output_1, output_2], dim=1)
    return output                                                               #(1x65x128x128)

"""Regular BottleNeck"""

def reg_bottleneck(image):
    projConv_R = projectionConv(6, 4, 1, 1)
    assymConv_R = assymetricConv(16, 32, 64, (1,2))
    expanConv_R = expansionConv(64, 4, 1, 1)
    m = nn.Dropout2d(p=0.2)
    output = torch.cat([image, m(expanConv_R(assymConv_R(projConv_R(image))))], dim=1)
    return output

"""Downsampling BottleNeck"""

def down_bottleneck(image):
    projConv_D = projectionConv(256, 4, 2, 1, 1)
    regConv_D = convBlock(64, 128, 5, 1, 2)
    expanConv_D = expansionConv(128, 4, 1, 1)
    output_1 = nn.MaxPool2d(kernel_size=2, stride=2)(regConv_D(projConv_D(image)))
    output_2 = nn.MaxPool2d(kernel_size=2, stride=2)(image)
    output = torch.cat([output_1, output_2], dim=1)
    return output

"""Upsampling BottleNech"""

def up_bottleneck(image):
    regConv_U = convBlock(384, 256, 5, 1)
    # output_1 = nn.MaxUnpool2d(kernel_size=2, stride=2)(regConv_U(image))
    projConv_U = projectionConv(384, 4, 1, 1)
    transConv_U = transConv(96, 192, 3, 1)
    expanConv_U = expansionConv(192, 4, 1, 1)
    output_2 = expanConv_U(transConv_U(projConv_U(image)))
    return output_2

image = torch.randn(1, 384, 128, 128)
out = up_bottleneck(image)
out.shape

